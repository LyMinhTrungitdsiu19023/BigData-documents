{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5mV-RU1g08b"
      },
      "source": [
        "# Add python files to Spark cluster\n",
        "\n",
        "The `SparkContext.addPyFiles()` function can be used to add py files. We can define objects and variables in these files and make them available to the Spark cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqppemAWgrvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8e8488-b60d-4cbc-fe38-3cfb58b8ee2e"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "\r                                                                               \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,039 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,519 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,334 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,294 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,568 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,094 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n",
            "Fetched 14.5 MB in 7s (2,034 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuDQGOOxgtqE"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext, SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext(conf=SparkConf())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "pTT94dwEguCe",
        "outputId": "c0edda24-0023-4e42-8f98-57a1137ce9bb"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20772bf5-0e7c-400c-8a06-63db7a96b86e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20772bf5-0e7c-400c-8a06-63db7a96b86e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_module.py to my_module.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'my_module.py': b'def addPyFiles_is_successfull():\\n    return(True)\\n\\ndef sum_two_variables(a, b):\\n    return(sum([a,b]))\\n    '}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJn_0XaiguFI"
      },
      "source": [
        "sc.addPyFile('./my_module.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "BYnsSl9WguHn",
        "outputId": "3257093f-440f-4820-f105-c5e56ee912cc"
      },
      "source": [
        "SparkFiles.get('my_module.py')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/spark-2b33888c-fd73-46e0-9c28-bb07c72787d7/userFiles-53df3eb6-762f-467d-b63e-edaf91718bf0/my_module.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7dQT8EFhq4M"
      },
      "source": [
        "# Use **my_module.py**\n",
        "We can import `my_module` as a python module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1JEJRiEguJm"
      },
      "source": [
        "from my_module import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z8MKV2NguMq",
        "outputId": "d11eb03f-8584-4316-b07d-0e8e02e0bd75"
      },
      "source": [
        "addPyFiles_is_successfull()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxPnBDVJY8qz",
        "outputId": "bad3ce73-8aaa-4473-d050-8524262e5023"
      },
      "source": [
        "!cat ./my_module.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def addPyFiles_is_successfull():\n",
            "    return(True)\n",
            "\n",
            "def sum_two_variables(a, b):\n",
            "    return(sum([a,b]))\n",
            "    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj16wRCrguOW",
        "outputId": "afd6656d-359a-41ee-ad75-d28265b7f988"
      },
      "source": [
        "sum_two_variables(4,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icgkn4qTguQd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1HBZfOIh2QZ"
      },
      "source": [
        "# Dense and sparse vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLLe0bAguTM"
      },
      "source": [
        "spark = SparkSession(sparkContext=sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63tcMUP4guWE"
      },
      "source": [
        "from pyspark.ml.linalg import Vector, DenseVector, SparseVector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxMjBrwbiIau"
      },
      "source": [
        "# Dense vector and sparse vector\n",
        "\n",
        "A vector can be represented in dense and sparse formats. A dense vector is a regular vector that has each elements printed. A sparse vector use three components to represent a vector but with less memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qiavzo-iF7S",
        "outputId": "bf0b87a3-c981-4603-b733-323e647d2858"
      },
      "source": [
        "dv = DenseVector([1.0,0.,0.,0.,4.5,0])\n",
        "dv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([1.0, 0.0, 0.0, 0.0, 4.5, 0.0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTMm93t4iRVu"
      },
      "source": [
        "## Three components of a sparse vector\n",
        "\n",
        "* vector size\n",
        "* indices of active elements\n",
        "* values of active elements\n",
        "\n",
        "In the above dense vector:\n",
        "\n",
        "* vector size = 6\n",
        "* indices of active elements = [0, 4]\n",
        "* values of active elements = [1.0, 4.5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvBS6duOiRZR"
      },
      "source": [
        "We can use the `SparseVector()` function to create a sparse vector. The first argument is the vector size, the second\n",
        "argument is a dictionary. The keys are indices of active elements and the values are values of active elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J6HVi9BiNnR",
        "outputId": "3d946bca-b072-4f80-c78d-1ecc1063e6bf"
      },
      "source": [
        "sv = SparseVector(6, {0:1.0, 4:4.5})\n",
        "sv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(6, {0: 1.0, 4: 4.5})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ASur7t8iX4C"
      },
      "source": [
        "## Convert sparse vector to dense vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwbbZ9eliOM3",
        "outputId": "85f33390-ccb7-4100-add1-b20c6e1c93fb"
      },
      "source": [
        "DenseVector(sv.toArray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([1.0, 0.0, 0.0, 0.0, 4.5, 0.0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqQ7fSaOieL8"
      },
      "source": [
        "## Convert dense vector to sparse vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-677xd_EiOPN",
        "outputId": "dcf19bf0-4531-4de7-984e-00bf81b61028"
      },
      "source": [
        "active_elements_dict = {index: value for index, value in enumerate(dv) if value != 0}\n",
        "active_elements_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0, 4: 4.5}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEenVpmbiORi",
        "outputId": "baf71e60-b062-4696-f8e8-99a55ebbef38"
      },
      "source": [
        "SparseVector(len(dv), active_elements_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(6, {0: 1.0, 4: 4.5})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj0eE5MCiOUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7608c5da-6ad9-41f1-92af-6b8c33cd10cb"
      },
      "source": [
        "# Quick exercise\n",
        "sv2 = SparseVector(10, {1:1.3, 6: 5, 9: 2.1})\n",
        "sv2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(10, {1: 1.3, 6: 5.0, 9: 2.1})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dv2 = DenseVector(sv2.toArray())\n",
        "dv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6eyMZaAGOFk",
        "outputId": "fe44f6b8-4749-445a-9b4a-4cf95d5190ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([0.0, 1.3, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRfq1XOVL0yc"
      },
      "source": [
        "# Pipeline\n",
        "\n",
        "Pipeline is a sequence of stages which consists of **Estimators** and/or **Transformers**. **Estimator** has **`fit`** method and **Transformer** has **`transform`** method. Therefore, we can say, **a pipeline is a sequence of `fit` and `transform` methods**. When it is a **`fit`** method, it applies to the input data and turns into a **`transform`** method. Then the **`transform`** method applies to the **fitted** data and output **transformed** data. **The transformed data output from previous stage has to be an acceptable input to the next stage's fit/transform method**.\n",
        "\n",
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qR2B169iOV-",
        "outputId": "26c67342-5f98-4589-8b69-c3c810f7f85a"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsJEcdGiOYy"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF_qJcEMMIwo"
      },
      "source": [
        "## Example\n",
        "\n",
        "We are going to use pipeline to `StringIndex` columns x1, x2, y1, and y2. Then we `OneHotEncode` the resulting `StringIdexed` columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC_QocTrMI9T",
        "outputId": "a1b375bc-4dd8-4678-9473-388b705a2c62"
      },
      "source": [
        "stringindex_stages = [StringIndexer(inputCol=c, outputCol='idx_' + c) for c in ['x1', 'x2', 'y1', 'y2']]\n",
        "stringindex_stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StringIndexer_c728dde5143f,\n",
              " StringIndexer_ae9f62ca2dcb,\n",
              " StringIndexer_fe861f4fa4fd,\n",
              " StringIndexer_b906d2cefdc1]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpX03F3TMJAC",
        "outputId": "ade49fa6-606e-4102-8657-9170a4587339"
      },
      "source": [
        "onehotencode_stages = [OneHotEncoder(inputCol='idx_' + c, outputCol='ohe_' + c) for c in ['x1', 'x2', 'y1', 'y2']]\n",
        "onehotencode_stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OneHotEncoder_3eb7cec4feef,\n",
              " OneHotEncoder_f657ebd84d6d,\n",
              " OneHotEncoder_e7f87bb48b12,\n",
              " OneHotEncoder_b6228bebf1df]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6_TQztEMSxb"
      },
      "source": [
        "Note that the **outputCol label** in StringIndex stages is the same as the **inputCol label** in the OneHotEncode stages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB4pnh95MS1g"
      },
      "source": [
        "## Elements in the stage list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0W4tKFUMJC2",
        "outputId": "60eaff89-2bfc-4ee0-df8a-2b4d6a2bf938"
      },
      "source": [
        "all_stages = stringindex_stages + onehotencode_stages\n",
        "[type(x) for x in all_stages]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[pyspark.ml.feature.StringIndexer,\n",
              " pyspark.ml.feature.StringIndexer,\n",
              " pyspark.ml.feature.StringIndexer,\n",
              " pyspark.ml.feature.StringIndexer,\n",
              " pyspark.ml.feature.OneHotEncoder,\n",
              " pyspark.ml.feature.OneHotEncoder,\n",
              " pyspark.ml.feature.OneHotEncoder,\n",
              " pyspark.ml.feature.OneHotEncoder]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpNrOCiJMbOI"
      },
      "source": [
        "In the above list, **`pyspark.ml.feature.StringIndexer`** is an **Estimator**(has a fit method) and **`pyspark.ml.feature.OneHotEncoder`** is a **transformer**(has a transform method)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP7LHVEoMbRV"
      },
      "source": [
        "## Build and run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60P5sM6CMJFL",
        "outputId": "de6b7b54-9c20-4486-8418-f210ab3e3adc"
      },
      "source": [
        "Pipeline(stages=all_stages).fit(df).transform(df).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|idx_x1|idx_x2|idx_y1|idx_y2|       ohe_x1|       ohe_x2|       ohe_y1|       ohe_y2|\n",
            "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|   1.0|   2.0|   1.0|   0.0|(2,[1],[1.0])|    (2,[],[])|    (1,[],[])|(1,[0],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|   1.0|   0.0|   0.0|   1.0|(2,[1],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|    (1,[],[])|\n",
            "|  b|orange|  2|3.5|  1| no|   0.0|   0.0|   1.0|   1.0|(2,[0],[1.0])|(2,[0],[1.0])|    (1,[],[])|    (1,[],[])|\n",
            "|  b|orange|  2|1.4|  0|yes|   0.0|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|   0.0|   1.0|   0.0|   0.0|(2,[0],[1.0])|(2,[1],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|   2.0|   1.0|   1.0|   0.0|    (2,[],[])|(2,[1],[1.0])|    (1,[],[])|(1,[0],[1.0])|\n",
            "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ED7WXzvMjJ2"
      },
      "source": [
        "## Reorder pipeline stages\n",
        "\n",
        "In the example above, our strategy is to **StringIndex** all four columns and then **OneHotEncode** them. Since each **OneHotEncode** stage only depends on the output of their corresponding **StringIndex** stage, our stages list could be **`[stringindexer on x1, onehotencoder on x1, stringindexer on x2, onehotencoder on x2, stringindexer on y1, onehotencoder on y1, stringindexer on y2, onehotencoder on y2]`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeJf7tOaMnn5"
      },
      "source": [
        "### Old stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFIQfmsqMJHp",
        "outputId": "b116ba33-20cf-4a14-d5d3-182584400570"
      },
      "source": [
        "all_stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StringIndexer_c728dde5143f,\n",
              " StringIndexer_ae9f62ca2dcb,\n",
              " StringIndexer_fe861f4fa4fd,\n",
              " StringIndexer_b906d2cefdc1,\n",
              " OneHotEncoder_3eb7cec4feef,\n",
              " OneHotEncoder_f657ebd84d6d,\n",
              " OneHotEncoder_e7f87bb48b12,\n",
              " OneHotEncoder_b6228bebf1df]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3iKrFitMyiG"
      },
      "source": [
        "### New stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMc6mOQ_Mysb",
        "outputId": "ab2cfd29-945a-4366-917c-0a8408150ba1"
      },
      "source": [
        "new_all_stages = [all_stages[x] for x in [0,4,1,5,2,6,3,7]]\n",
        "new_all_stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StringIndexer_c728dde5143f,\n",
              " OneHotEncoder_3eb7cec4feef,\n",
              " StringIndexer_ae9f62ca2dcb,\n",
              " OneHotEncoder_f657ebd84d6d,\n",
              " StringIndexer_fe861f4fa4fd,\n",
              " OneHotEncoder_e7f87bb48b12,\n",
              " StringIndexer_b906d2cefdc1,\n",
              " OneHotEncoder_b6228bebf1df]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4qmwOBM4dj"
      },
      "source": [
        "## Build and run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNWhUUS0Myv6",
        "outputId": "352c4a80-cf73-43be-fcc4-6ac1f53a2783"
      },
      "source": [
        "Pipeline(stages=new_all_stages).fit(df).transform(df).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|idx_x1|       ohe_x1|idx_x2|       ohe_x2|idx_y1|       ohe_y1|idx_y2|       ohe_y2|\n",
            "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|   1.0|(2,[1],[1.0])|   2.0|    (2,[],[])|   1.0|    (1,[],[])|   0.0|(1,[0],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|   1.0|(2,[1],[1.0])|   0.0|(2,[0],[1.0])|   0.0|(1,[0],[1.0])|   1.0|    (1,[],[])|\n",
            "|  b|orange|  2|3.5|  1| no|   0.0|(2,[0],[1.0])|   0.0|(2,[0],[1.0])|   1.0|    (1,[],[])|   1.0|    (1,[],[])|\n",
            "|  b|orange|  2|1.4|  0|yes|   0.0|(2,[0],[1.0])|   0.0|(2,[0],[1.0])|   0.0|(1,[0],[1.0])|   0.0|(1,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|   0.0|(2,[0],[1.0])|   1.0|(2,[1],[1.0])|   0.0|(1,[0],[1.0])|   0.0|(1,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|   2.0|    (2,[],[])|   1.0|(2,[1],[1.0])|   1.0|    (1,[],[])|   0.0|(1,[0],[1.0])|\n",
            "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9XRMI1kMyxv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2d7bXxdM8um"
      },
      "source": [
        "# SQL functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "npazqtHmMy0W",
        "outputId": "9b50609a-f689-4b16-9bf0-079b43005938"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f7f8e9f-6fc3-45a4-a3f1-ff935e4e61c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f7f8e9f-6fc3-45a4-a3f1-ff935e4e61c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving prostate.csv to prostate.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prostate.csv': b'lcavol,lweight,age,lbph,svi,lcp,gleason,pgg45,lpsa\\r-0.579818495,2.769458829,50,-1.386294361,0,-1.386294361,6,0,-0.430782916\\r-0.994252273,3.319625728,58,-1.386294361,0,-1.386294361,6,0,-0.162518929\\r-0.510825624,2.691243083,74,-1.386294361,0,-1.386294361,7,20,-0.162518929\\r-1.203972804,3.282789151,58,-1.386294361,0,-1.386294361,6,0,-0.162518929\\r0.751416089,3.432372999,62,-1.386294361,0,-1.386294361,6,0,0.371563556\\r-1.049822124,3.228826156,50,-1.386294361,0,-1.386294361,6,0,0.765467842\\r0.737164066,3.473518043,64,0.615185639,0,-1.386294361,6,0,0.765467842\\r0.693147181,3.539508997,58,1.53686722,0,-1.386294361,6,0,0.854415328\\r-0.776528789,3.539508997,47,-1.386294361,0,-1.386294361,6,0,1.047318994\\r0.223143551,3.244543572,63,-1.386294361,0,-1.386294361,6,0,1.047318994\\r0.254642218,3.604138226,65,-1.386294361,0,-1.386294361,6,0,1.266947603\\r-1.347073648,3.598681186,63,1.266947603,0,-1.386294361,6,0,1.266947603\\r1.613429934,3.022860941,63,-1.386294361,0,-0.597837001,7,30,1.266947603\\r1.477048724,2.998229154,67,-1.386294361,0,-1.386294361,7,5,1.348073148\\r1.205970807,3.442019376,57,-1.386294361,0,-0.430782916,7,5,1.398716881\\r1.541159072,3.06105174,66,-1.386294361,0,-1.386294361,6,0,1.446918983\\r-0.415515444,3.516013056,70,1.244154594,0,-0.597837001,7,30,1.470175845\\r2.288486169,3.649358696,66,-1.386294361,0,0.371563556,6,0,1.492904096\\r-0.562118918,3.267665989,41,-1.386294361,0,-1.386294361,6,0,1.558144618\\r0.182321557,3.825375199,70,1.658228077,0,-1.386294361,6,0,1.599387577\\r1.147402453,3.419364686,59,-1.386294361,0,-1.386294361,6,0,1.638996715\\r2.059238834,3.501042717,60,1.474763009,0,1.348073148,7,20,1.658228077\\r-0.544727175,3.375879574,59,-0.798507696,0,-1.386294361,6,0,1.695615609\\r1.781709133,3.451573589,63,0.438254931,0,1.178654996,7,60,1.713797928\\r0.385262401,3.667400422,69,1.599387577,0,-1.386294361,6,0,1.731655545\\r1.446918983,3.124565145,68,0.300104592,0,-1.386294361,6,0,1.766441661\\r0.512823626,3.719651113,65,-1.386294361,0,-0.798507696,7,70,1.800058272\\r-0.400477567,3.865979067,67,1.816452082,0,-1.386294361,7,20,1.816452082\\r1.040276712,3.128951117,67,0.223143551,0,0.048790164,7,80,1.848454813\\r2.409644165,3.375879574,65,-1.386294361,0,1.619388243,6,0,1.894616855\\r0.285178942,4.090169191,65,1.962907725,0,-0.798507696,6,0,1.924248652\\r0.182321557,6.107579526,65,1.704748092,0,-1.386294361,6,0,2.008214032\\r1.2753628,3.037353948,71,1.266947603,0,-1.386294361,6,0,2.008214032\\r0.009950331,3.267665989,54,-1.386294361,0,-1.386294361,6,0,2.021547563\\r-0.010050336,3.216873822,63,-1.386294361,0,-0.798507696,6,0,2.047692843\\r1.30833282,4.119849853,64,2.171336806,0,-1.386294361,7,5,2.085672091\\r1.423108334,3.657130756,73,-0.579818495,0,1.658228077,8,15,2.157559321\\r0.457424847,2.374905755,64,-1.386294361,0,-1.386294361,7,15,2.191653532\\r2.660958594,4.085135623,68,1.373715579,1,1.832581464,7,35,2.213753879\\r0.797507196,3.013080912,56,0.936093359,0,-0.162518929,7,5,2.277267285\\r0.620576488,3.141994781,60,-1.386294361,0,-1.386294361,9,80,2.297572551\\r1.442201993,3.682609841,68,-1.386294361,0,-1.386294361,7,10,2.307572635\\r0.58221562,3.865979067,62,1.713797928,0,-0.430782916,6,0,2.327277706\\r1.771556762,3.896909368,61,-1.386294361,0,0.810930216,7,6,2.374905755\\r1.486139696,3.409496184,66,1.749199855,0,-0.430782916,7,20,2.521720623\\r1.663926098,3.392829132,61,0.615185639,0,-1.386294361,7,15,2.553343811\\r2.727852828,3.995444614,79,1.87946505,1,2.656756907,9,100,2.568788134\\r1.16315081,4.035125203,68,1.713797928,0,-0.430782916,7,40,2.568788134\\r1.745715531,3.498021566,43,-1.386294361,0,-1.386294361,6,0,2.591516385\\r1.220829921,3.568123253,70,1.373715579,0,-0.798507696,6,0,2.591516385\\r1.091923301,3.993602992,68,-1.386294361,0,-1.386294361,7,50,2.656756907\\r1.660131027,4.23483088,64,2.073171929,0,-1.386294361,6,0,2.677590994\\r0.512823626,3.63363098,64,1.492904096,0,0.048790164,7,70,2.684440335\\r2.12704052,4.12147323,68,1.766441661,0,1.446918983,7,40,2.691243083\\r3.153590358,3.516013056,59,-1.386294361,0,-1.386294361,7,5,2.7047113\\r1.266947603,4.280132327,66,2.122261539,0,-1.386294361,7,15,2.718000532\\r0.97455964,2.86505395,47,-1.386294361,0,0.500775288,7,4,2.788092909\\r0.463734016,3.764682418,49,1.423108334,0,-1.386294361,6,0,2.794227897\\r0.542324291,4.178226046,70,0.438254931,0,-1.386294361,7,20,2.806386102\\r1.061256502,3.851210866,61,1.294727168,0,-1.386294361,7,40,2.812410216\\r0.457424847,4.524502283,73,2.32630162,0,-1.386294361,6,0,2.841998174\\r1.997417706,3.719651113,63,1.619388243,1,1.909542505,7,40,2.853592506\\r2.77570885,3.524888854,72,-1.386294361,0,1.558144618,9,95,2.853592506\\r2.034705648,3.917010547,66,2.008214032,1,2.1102132,7,60,2.882003508\\r2.073171929,3.62300671,64,-1.386294361,0,-1.386294361,6,0,2.882003508\\r1.458615023,3.836221292,61,1.32175584,0,-0.430782916,7,20,2.887590115\\r2.02287119,3.878466222,68,1.78339122,0,1.32175584,7,70,2.920469789\\r2.198335072,4.050915004,72,2.307572635,0,-0.430782916,7,10,2.962692419\\r-0.446287103,4.408546844,69,-1.386294361,0,-1.386294361,6,0,2.962692419\\r1.193922468,4.780383204,72,2.32630162,0,-0.798507696,7,5,2.972975286\\r1.864080131,3.593194204,60,-1.386294361,1,1.32175584,7,60,3.013080912\\r1.160020917,3.341093458,77,1.749199855,0,-1.386294361,7,25,3.037353948\\r1.214912744,3.825375199,69,-1.386294361,1,0.223143551,7,20,3.056356895\\r1.838961071,3.236715743,60,0.438254931,1,1.178654996,9,90,3.075005454\\r2.999226163,3.849083206,69,-1.386294361,1,1.909542505,7,20,3.275256158\\r3.141130476,3.263849191,68,-0.051293294,1,2.420368129,7,50,3.337547355\\r2.010894999,4.433788569,72,2.122261539,0,0.500775288,7,60,3.392829132\\r2.537657215,4.354783898,78,2.32630162,0,-1.386294361,7,10,3.435598808\\r2.648300197,3.582129084,69,-1.386294361,1,2.583997552,7,70,3.457892725\\r2.779440197,3.823191792,63,-1.386294361,0,0.371563556,7,50,3.513036863\\r1.467874348,3.070375817,66,0.559615788,0,0.223143551,7,40,3.516013056\\r2.513656063,3.473518043,57,0.438254931,0,2.327277706,7,60,3.530762586\\r2.613006652,3.888754378,77,-0.527632742,1,0.559615788,7,30,3.565298392\\r2.677590994,3.838376465,65,1.115141591,0,1.749199855,9,70,3.570940156\\r1.562346305,3.709906821,60,1.695615609,0,0.810930216,7,30,3.587676949\\r3.302849259,3.518980417,64,-1.386294361,1,2.327277706,7,60,3.630985476\\r2.024193067,3.731699451,58,1.638996715,0,-1.386294361,6,0,3.680090948\\r1.731655545,3.369018483,62,-1.386294361,1,0.300104592,7,30,3.71235181\\r2.807593831,4.718052343,65,-1.386294361,1,2.463853241,7,60,3.984343667\\r1.562346305,3.695110004,76,0.936093359,1,0.810930216,7,75,3.993602992\\r3.246490992,4.101816577,68,-1.386294361,0,-1.386294361,6,0,4.029806041\\r2.532902848,3.677565694,61,1.348073148,1,-1.386294361,7,15,4.129550818\\r2.830267834,3.876395828,68,-1.386294361,1,1.32175584,7,60,4.385146762\\r3.821003607,3.896909368,44,-1.386294361,1,2.1690537,7,40,4.684443367\\r2.907447359,3.39618484,52,-1.386294361,1,2.463853241,7,10,5.143124477\\r2.882563575,3.773909703,68,1.558144618,1,1.558144618,7,80,5.47750903\\r3.471966453,3.974997805,68,0.438254931,1,2.90416508,7,20,5.58293224'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh97g-33My22",
        "outputId": "ac45c2d3-48ed-4983-928e-a88c252ade95"
      },
      "source": [
        "iris = spark.read.csv('./iris.csv', header=True, inferSchema=True)\n",
        "iris.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-5pwpJoMJKc",
        "outputId": "fa7ad390-b9ff-4475-f57b-cfd1c493ea25"
      },
      "source": [
        "prostate = spark.read.csv('./prostate.csv', header=True, inferSchema=True)\n",
        "prostate.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|      lcavol|    lweight|age|        lbph|svi|         lcp|gleason|pgg45|        lpsa|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|-0.579818495|2.769458829| 50|-1.386294361|  0|-1.386294361|      6|    0|-0.430782916|\n",
            "|-0.994252273|3.319625728| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-0.510825624|2.691243083| 74|-1.386294361|  0|-1.386294361|      7|   20|-0.162518929|\n",
            "|-1.203972804|3.282789151| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "| 0.751416089|3.432372999| 62|-1.386294361|  0|-1.386294361|      6|    0| 0.371563556|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OT97szliOkd"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l04z_YKNpND",
        "outputId": "3886b717-e023-4f0b-8c47-ec9321aceece"
      },
      "source": [
        "prostate.select('lpsa', abs(prostate.lpsa).alias('abs(lpsa)')).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|        lpsa|  abs(lpsa)|\n",
            "+------------+-----------+\n",
            "|-0.430782916|0.430782916|\n",
            "|-0.162518929|0.162518929|\n",
            "|-0.162518929|0.162518929|\n",
            "|-0.162518929|0.162518929|\n",
            "| 0.371563556|0.371563556|\n",
            "+------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Q25zvcNxRO"
      },
      "source": [
        "## `acos`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA-SgI51NpXN",
        "outputId": "220736d0-1b52-4d1e-f06c-6a9d7d02d788"
      },
      "source": [
        "pdf = pd.DataFrame({\n",
        "    'x': list(-np.random.rand(5)) + list(np.random.rand(5))\n",
        "})\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                   x|\n",
            "+--------------------+\n",
            "|-0.02561841650378...|\n",
            "| -0.9511210096302304|\n",
            "|-0.30015015484867946|\n",
            "| -0.7542980823549114|\n",
            "|-0.04565449400795207|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwgy85FTNpZC",
        "outputId": "840c84ab-7609-45ae-e8b3-2b3c7dafad3f"
      },
      "source": [
        "df.select('x', acos(df.x)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                   x|           ACOS(x)|\n",
            "+--------------------+------------------+\n",
            "|-0.02561841650378...|1.5964175463683339|\n",
            "| -0.9511210096302304| 2.827642160120233|\n",
            "|-0.30015015484867946|1.8756463897580689|\n",
            "| -0.7542980823549114| 2.425380659457947|\n",
            "|-0.04565449400795207| 1.616466695557147|\n",
            "+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZDuoQs4N-gM"
      },
      "source": [
        "## `add_months`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJv9b7GeNpb6"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7UsSZEpN5nw",
        "outputId": "4c648e38-f0f2-4194-f125-f3bfb40e5b13"
      },
      "source": [
        "base = datetime.date.today()\n",
        "date_list = [base + datetime.timedelta(days=x) for x in list(range(0, 10))*10]\n",
        "pdf = pd.DataFrame({\n",
        "    'dates': date_list\n",
        "})\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|     dates|\n",
            "+----------+\n",
            "|2022-12-02|\n",
            "|2022-12-03|\n",
            "|2022-12-04|\n",
            "|2022-12-05|\n",
            "|2022-12-06|\n",
            "+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LJ7gnfPN5rB",
        "outputId": "1a00e24e-a7d6-4d48-a70d-50b8052fa238"
      },
      "source": [
        "df.select('dates', add_months(df.dates, 2).alias('new_dates')).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|     dates| new_dates|\n",
            "+----------+----------+\n",
            "|2022-12-02|2023-02-02|\n",
            "|2022-12-03|2023-02-03|\n",
            "|2022-12-04|2023-02-04|\n",
            "|2022-12-05|2023-02-05|\n",
            "|2022-12-06|2023-02-06|\n",
            "+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXqPhs9aOILj"
      },
      "source": [
        "## `approx_count_distinct`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5AmwDjwN5tX",
        "outputId": "3ad4b5ac-482d-47e9-b919-14442ba13af5"
      },
      "source": [
        "prostate.select(approx_count_distinct(prostate.gleason)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|approx_count_distinct(gleason)|\n",
            "+------------------------------+\n",
            "|                             4|\n",
            "+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acz6w9vFN5vf",
        "outputId": "6556f011-ce51-497b-c4c3-484089a1933d"
      },
      "source": [
        "iris.select(approx_count_distinct(iris.species)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|approx_count_distinct(species)|\n",
            "+------------------------------+\n",
            "|                             3|\n",
            "+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex1L2dCGON1J"
      },
      "source": [
        "## `array`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pknyxcH1N5x4",
        "outputId": "fc13a008-1d62-4761-8cc2-39238d21afcb"
      },
      "source": [
        "iris.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0BOxtLpN5zP",
        "outputId": "4c8b55f8-22ec-4291-9e6a-fb789f8687b1"
      },
      "source": [
        "df_arr = iris.select('species', array(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']).alias('features'))\n",
        "df_arr.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|species|            features|\n",
            "+-------+--------------------+\n",
            "| setosa|[5.1, 3.5, 1.4, 0.2]|\n",
            "| setosa|[4.9, 3.0, 1.4, 0.2]|\n",
            "| setosa|[4.7, 3.2, 1.3, 0.2]|\n",
            "| setosa|[4.6, 3.1, 1.5, 0.2]|\n",
            "| setosa|[5.0, 3.6, 1.4, 0.2]|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niNPQFS2OYR_"
      },
      "source": [
        "## `array_contains`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaOqHASuN51i",
        "outputId": "c361fb75-5e5c-492d-e2e0-b1192c7b229b"
      },
      "source": [
        "df = df_arr.select('species', 'features', array_contains(df_arr.features, 1.4).alias('new_features'))\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------------+\n",
            "|species|            features|new_features|\n",
            "+-------+--------------------+------------+\n",
            "| setosa|[5.1, 3.5, 1.4, 0.2]|        true|\n",
            "| setosa|[4.9, 3.0, 1.4, 0.2]|        true|\n",
            "| setosa|[4.7, 3.2, 1.3, 0.2]|       false|\n",
            "| setosa|[4.6, 3.1, 1.5, 0.2]|       false|\n",
            "| setosa|[5.0, 3.6, 1.4, 0.2]|        true|\n",
            "+-------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S42Ct00OVmV",
        "outputId": "15dd0b10-dbb9-49ac-f43d-d8fc85022d96"
      },
      "source": [
        "df.filter(df.new_features).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------------+\n",
            "|species|            features|new_features|\n",
            "+-------+--------------------+------------+\n",
            "| setosa|[5.1, 3.5, 1.4, 0.2]|        true|\n",
            "| setosa|[4.9, 3.0, 1.4, 0.2]|        true|\n",
            "| setosa|[5.0, 3.6, 1.4, 0.2]|        true|\n",
            "| setosa|[4.6, 3.4, 1.4, 0.3]|        true|\n",
            "| setosa|[4.4, 2.9, 1.4, 0.2]|        true|\n",
            "+-------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56lqfo9QOf9c"
      },
      "source": [
        "## `asc`\n",
        "\n",
        "`asc` returns a **sort expression**, which can be used as argument of sort functions such as `pyspark.sql.DataFrame.sort` and `pyspark.sql.DataFrame.orderBy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZGLIqx8OVpE",
        "outputId": "1d74cfd2-3923-4c02-effb-e86efef17fe1"
      },
      "source": [
        "prostate.sort(prostate.lpsa.asc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|      lcavol|    lweight|age|        lbph|svi|         lcp|gleason|pgg45|        lpsa|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|-0.579818495|2.769458829| 50|-1.386294361|  0|-1.386294361|      6|    0|-0.430782916|\n",
            "|-0.994252273|3.319625728| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-1.203972804|3.282789151| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-0.510825624|2.691243083| 74|-1.386294361|  0|-1.386294361|      7|   20|-0.162518929|\n",
            "| 0.751416089|3.432372999| 62|-1.386294361|  0|-1.386294361|      6|    0| 0.371563556|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPlZy-ifOVsu",
        "outputId": "262c58b3-6621-4dce-fa7d-9cbbb5aca132"
      },
      "source": [
        "prostate.orderBy(prostate.lpsa.asc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|      lcavol|    lweight|age|        lbph|svi|         lcp|gleason|pgg45|        lpsa|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|-0.579818495|2.769458829| 50|-1.386294361|  0|-1.386294361|      6|    0|-0.430782916|\n",
            "|-0.994252273|3.319625728| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-1.203972804|3.282789151| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-0.510825624|2.691243083| 74|-1.386294361|  0|-1.386294361|      7|   20|-0.162518929|\n",
            "| 0.751416089|3.432372999| 62|-1.386294361|  0|-1.386294361|      6|    0| 0.371563556|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXpd0C7iOpYu"
      },
      "source": [
        "Find more:\n",
        "\n",
        "* `ascii`\n",
        "* `asin`\n",
        "* `atan`\n",
        "* `atan2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDDhy_w3OvRg"
      },
      "source": [
        "## `avg`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fly9s4vOVvC",
        "outputId": "29cf99a7-f742-455c-ce52-499c481cdc92"
      },
      "source": [
        "prostate.select(avg(prostate.lpsa)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|         avg(lpsa)|\n",
            "+------------------+\n",
            "|2.4783868787422683|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX8ezoT2N54C",
        "outputId": "3fbb6b40-0c1b-4c35-ff74-dd065413c6dd"
      },
      "source": [
        "# `cbrt`\n",
        "\n",
        "prostate.select('lpsa', cbrt(prostate.lpsa)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+\n",
            "|        lpsa|         CBRT(lpsa)|\n",
            "+------------+-------------------+\n",
            "|-0.430782916|-0.7552420410177275|\n",
            "|-0.162518929|-0.5457176294010901|\n",
            "|-0.162518929|-0.5457176294010901|\n",
            "|-0.162518929|-0.5457176294010901|\n",
            "| 0.371563556| 0.7189152621521183|\n",
            "+------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqSHTUMdN58E",
        "outputId": "be9bacd8-0c6e-4443-ffc8-199bf600895c"
      },
      "source": [
        "# `ceil`\n",
        "prostate.select('lpsa', ceil(prostate.lpsa)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|        lpsa|CEIL(lpsa)|\n",
            "+------------+----------+\n",
            "|-0.430782916|         0|\n",
            "|-0.162518929|         0|\n",
            "|-0.162518929|         0|\n",
            "|-0.162518929|         0|\n",
            "| 0.371563556|         1|\n",
            "+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzlU8T_XPImZ"
      },
      "source": [
        "## `coalesce`\n",
        "\n",
        "Return the first column that is not null."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTdfjyt9PEn5",
        "outputId": "a9b36e24-8ff6-445c-8ef0-5cd7385133c1"
      },
      "source": [
        "df = spark.createDataFrame([(None, None), (1, None), (None, 2)], (\"a\", \"b\"))\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|   a|   b|\n",
            "+----+----+\n",
            "|null|null|\n",
            "|   1|null|\n",
            "|null|   2|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cCIc3tLPLEI",
        "outputId": "46372c03-cf14-425e-e2ab-98f4481f7501"
      },
      "source": [
        "df.select(coalesce(df.a, df.b)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|coalesce(a, b)|\n",
            "+--------------+\n",
            "|          null|\n",
            "|             1|\n",
            "|             2|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWENJx02PNt4"
      },
      "source": [
        "## `col`\n",
        "\n",
        "Returns a **Column** based on the given column name. It can save your some typing when the dataframe is very long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMZUkM7lPNDH",
        "outputId": "46b0432e-a20b-4a66-95d8-26ccc1b42b96"
      },
      "source": [
        "prostate.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|      lcavol|    lweight|age|        lbph|svi|         lcp|gleason|pgg45|        lpsa|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|-0.579818495|2.769458829| 50|-1.386294361|  0|-1.386294361|      6|    0|-0.430782916|\n",
            "|-0.994252273|3.319625728| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-0.510825624|2.691243083| 74|-1.386294361|  0|-1.386294361|      7|   20|-0.162518929|\n",
            "|-1.203972804|3.282789151| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "| 0.751416089|3.432372999| 62|-1.386294361|  0|-1.386294361|      6|    0| 0.371563556|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KB317OxPSwX",
        "outputId": "4f2e9cd1-aa19-44f2-fc78-21c38128ed6c"
      },
      "source": [
        "prostate.select(col('lcavol'), col('age')).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---+\n",
            "|      lcavol|age|\n",
            "+------------+---+\n",
            "|-0.579818495| 50|\n",
            "|-0.994252273| 58|\n",
            "|-0.510825624| 74|\n",
            "|-1.203972804| 58|\n",
            "| 0.751416089| 62|\n",
            "+------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeN6io0WPaOL"
      },
      "source": [
        "## `collect_list`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJy3R3yGPVgQ",
        "outputId": "73f8afd0-8733-4b60-cf2c-1ab191639582"
      },
      "source": [
        "pdf = pd.DataFrame({\n",
        "    'x':[1, 2, 2, 3, 4,4,4,4]\n",
        "})\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|  x|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "|  4|\n",
            "|  4|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWl8jqPRPcQQ",
        "outputId": "eb2aedf6-49ff-467c-b965-052e9982be01"
      },
      "source": [
        "df.select(collect_list(df.x)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|     collect_list(x)|\n",
            "+--------------------+\n",
            "|[1, 2, 2, 3, 4, 4...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuGbEUySPecZ",
        "outputId": "6c34f4be-8928-43bf-a95d-9a0421be957d"
      },
      "source": [
        "# `collect_set`\n",
        "df.select(collect_set(df.x)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|collect_set(x)|\n",
            "+--------------+\n",
            "|  [1, 2, 3, 4]|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQeKwZRPPmAu"
      },
      "source": [
        "## `concat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckTTClJJPi5i",
        "outputId": "653f78d2-cfc3-482a-f6e5-f8314864c9b5"
      },
      "source": [
        "df = spark.createDataFrame([['a', '1'], ['b', '2']], ['x', 'v'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "|  x|  v|\n",
            "+---+---+\n",
            "|  a|  1|\n",
            "|  b|  2|\n",
            "+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5SYPlocPnhq",
        "outputId": "cfd69dcd-6b1e-480a-c1d6-612659d91c0d"
      },
      "source": [
        "df.select('x', 'v', concat(df.x, df.v).alias('concate(x,v)')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------------+\n",
            "|  x|  v|concate(x,v)|\n",
            "+---+---+------------+\n",
            "|  a|  1|          a1|\n",
            "|  b|  2|          b2|\n",
            "+---+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da2lyFp_PqWG"
      },
      "source": [
        "## `concat_ws`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saYAbQRCPpq7",
        "outputId": "83810f6b-4e54-4ec0-9c92-e177a85b8dd0"
      },
      "source": [
        "df.select('x', 'v', concat_ws('_', df.x, df.v).alias('concate(x,v)')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------------+\n",
            "|  x|  v|concate(x,v)|\n",
            "+---+---+------------+\n",
            "|  a|  1|         a_1|\n",
            "|  b|  2|         b_2|\n",
            "+---+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqWDeUv4P12-"
      },
      "source": [
        "## `corr`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERU0h1h9Puxj",
        "outputId": "9d952f67-d36a-429c-f87a-05629f7b6a05"
      },
      "source": [
        "prostate.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|      lcavol|    lweight|age|        lbph|svi|         lcp|gleason|pgg45|        lpsa|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "|-0.579818495|2.769458829| 50|-1.386294361|  0|-1.386294361|      6|    0|-0.430782916|\n",
            "|-0.994252273|3.319625728| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "|-0.510825624|2.691243083| 74|-1.386294361|  0|-1.386294361|      7|   20|-0.162518929|\n",
            "|-1.203972804|3.282789151| 58|-1.386294361|  0|-1.386294361|      6|    0|-0.162518929|\n",
            "| 0.751416089|3.432372999| 62|-1.386294361|  0|-1.386294361|      6|    0| 0.371563556|\n",
            "+------------+-----------+---+------------+---+------------+-------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEt_g5dVPyn0",
        "outputId": "671087ac-6122-4aeb-a8fa-e59cd77bb4ec"
      },
      "source": [
        "prostate.select(corr(prostate.age, prostate.lpsa)).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|    corr(age, lpsa)|\n",
            "+-------------------+\n",
            "|0.16959284228582772|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqdJq502P3oc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig0tuOadP7ZG",
        "outputId": "a00b268e-0c8d-4319-92ec-b464c4177418"
      },
      "source": [
        "# `count`\n",
        "prostate.select(count(prostate.lpsa)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|count(lpsa)|\n",
            "+-----------+\n",
            "|         97|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "020ndR4zQGmy"
      },
      "source": [
        "## `covar_pop`\n",
        "\n",
        "**population covariance**: $\\frac{1}{n}\\sum_{i=1}^n(x_{i} - \\bar{x})(y_{i} - \\bar{y})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_5OvSodP7cn",
        "outputId": "197ab25d-5768-425d-e6be-eafece258866"
      },
      "source": [
        "prostate.select(covar_pop(prostate.age, prostate.lpsa)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|covar_pop(age, lpsa)|\n",
            "+--------------------+\n",
            "|  1.4424746293984458|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq5c8JrzQKB9"
      },
      "source": [
        "## `covar_samp`\n",
        "**sample covariance**: $\\frac{1}{n-1}\\sum_{i=1}^n(x_{i} - \\bar{x})(y_{i} - \\bar{y})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-wD9TaSQKME",
        "outputId": "ff569c95-6a9f-48c4-9f91-017db7a2adde"
      },
      "source": [
        "prostate.select(covar_samp(prostate.age, prostate.lpsa)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|covar_samp(age, lpsa)|\n",
            "+---------------------+\n",
            "|   1.4575004067880128|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rlZ9MlpQRF7"
      },
      "source": [
        "## `create_map`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFr7cMl4QJYr",
        "outputId": "a671b772-768b-47c2-e03a-ce06af2b1ec3"
      },
      "source": [
        "iris.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEVK5CHFQVX0",
        "outputId": "d66266b9-e8b3-4e65-9c40-28dc2aaa179c"
      },
      "source": [
        "df = iris.select(create_map('species', 'sepal_length'))\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|map(species, sepal_length)|\n",
            "+--------------------------+\n",
            "|           {setosa -> 5.1}|\n",
            "|           {setosa -> 4.9}|\n",
            "|           {setosa -> 4.7}|\n",
            "|           {setosa -> 4.6}|\n",
            "|           {setosa -> 5.0}|\n",
            "+--------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKyRO48IQYU-",
        "outputId": "ae89bf3a-2071-485e-cde0-f4fdac6cec42"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('map(species, sepal_length)', 'map<string,double>')]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPoMjLt-Qf-5"
      },
      "source": [
        "## `current_date`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcnW6kopQaVl",
        "outputId": "4ef6968f-e8fe-41f6-a892-88f088b169e8"
      },
      "source": [
        "df = spark.createDataFrame([[1],[2],[3],[4]], ['x'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|  x|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOKLM4vOQiWe",
        "outputId": "a21ad16e-461c-405e-a37f-2a3be75dd25d"
      },
      "source": [
        "df.select('x', current_date()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------+\n",
            "|  x|current_date()|\n",
            "+---+--------------+\n",
            "|  1|    2022-12-02|\n",
            "|  2|    2022-12-02|\n",
            "|  3|    2022-12-02|\n",
            "|  4|    2022-12-02|\n",
            "+---+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9tKQJeJQohV"
      },
      "source": [
        "## `current_tmestamp`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-juQGeTQkX9",
        "outputId": "1345a45e-8dbe-4eb4-fe93-264ddf427e4a"
      },
      "source": [
        "df.select('x', current_timestamp()).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------+\n",
            "|x  |current_timestamp()    |\n",
            "+---+-----------------------+\n",
            "|1  |2022-12-02 04:54:16.886|\n",
            "|2  |2022-12-02 04:54:16.886|\n",
            "|3  |2022-12-02 04:54:16.886|\n",
            "|4  |2022-12-02 04:54:16.886|\n",
            "+---+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XpersMsQrYO"
      },
      "source": [
        "## `date_add`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_0N5yjPQqje",
        "outputId": "e1f7fa9e-5007-4cf3-c5f6-5d4861a7532b"
      },
      "source": [
        "df2 = df.select('x', current_date().alias('current_date'))\n",
        "df2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+\n",
            "|  x|current_date|\n",
            "+---+------------+\n",
            "|  1|  2022-12-02|\n",
            "|  2|  2022-12-02|\n",
            "|  3|  2022-12-02|\n",
            "|  4|  2022-12-02|\n",
            "+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8CEHYMpQwtG",
        "outputId": "13318aaf-efbb-482a-c70a-709c876238a8"
      },
      "source": [
        "df2.select('x', 'current_date', date_add(df2.current_date, 10)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+--------------------------+\n",
            "|  x|current_date|date_add(current_date, 10)|\n",
            "+---+------------+--------------------------+\n",
            "|  1|  2022-12-02|                2022-12-12|\n",
            "|  2|  2022-12-02|                2022-12-12|\n",
            "|  3|  2022-12-02|                2022-12-12|\n",
            "|  4|  2022-12-02|                2022-12-12|\n",
            "+---+------------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vg8ZVRzQ2Cr"
      },
      "source": [
        "## `date_format`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpKVJZgWQy23",
        "outputId": "71e4c002-34fa-4453-fc1b-6bb9fac4a424"
      },
      "source": [
        "df2.select('x', 'current_date', date_format('current_date', 'MM/dd/yyyy').alias('new_date')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+----------+\n",
            "|  x|current_date|  new_date|\n",
            "+---+------------+----------+\n",
            "|  1|  2022-12-02|12/02/2022|\n",
            "|  2|  2022-12-02|12/02/2022|\n",
            "|  3|  2022-12-02|12/02/2022|\n",
            "|  4|  2022-12-02|12/02/2022|\n",
            "+---+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT2xAOK0Q4cY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQtNTJxdRHHE"
      },
      "source": [
        "# TF, IDF and TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0w88PjdRI-g"
      },
      "source": [
        "* TF is short for **Term Frequency**. It is simply the frequency of a term in a document. The higher the TF is for a specific term, the more important that term is to that document.\n",
        "\n",
        "* IDF is short for **Inverse Document Frequency**. It is the frequency of documents that contain a specific term. If a term exists in every single document, then the Document Frequency is the largest and is 1. And the Inverse Document Frequency will be the smallest. In the situation, this term is non-informative for classifying the documents.The IDF is a measure of the relevance of a term. The higher the IDF is, the more relavant the term is.\n",
        "\n",
        "* TF-IDF is the product of TF and IDF. A high TF-IDF is obtained when the The Term Frequency is high and the Document Frequency is low (IDF is high).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kda-kgG2RNgV"
      },
      "source": [
        "# Term Frequency, HashingTF and CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cGJ2mxORNcm"
      },
      "source": [
        "Pyspark has two functions to calculate term frequencies from documents: the **`HashingTF()`** and the **`CountVectorizer()`**. These two functions do two things:\n",
        "\n",
        "1. Indexing terms: converting words to numbers.\n",
        "2. Calculate term frequencies for each documents.\n",
        "\n",
        "The `HashingTF()` utilizes the Murmurhash 3 function to map a raw feature (a term) into an index (a number). Hashing is the process of transforming data of arbitrary size to size-fixed, usually shorter data. The term frequencies are calculated based on the generated indices. For the  HashingTF() method, the mapping process is very cheap. Because each term-to-index mapping is independent of other term-to-index mapping. The hashing function takes a unique input and gerenate a “unique result”. However, **hashing collision** may occur, which means different features (terms) may be hased to the same index.\n",
        "\n",
        "The **`CountVectorizer()`** indexes terms by descending order of term frequencies in the entire corpus, NOT the term frequencies in the document. After the indexing process, the term frequencies are calculated by documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yq8EwwJRHS_",
        "outputId": "0864b075-0dc5-4f2d-f3ce-624b8b44bed4"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'terms': [\n",
        "            ['spark', 'spark', 'spark', 'is', 'awesome', 'awesome'],\n",
        "            ['I', 'love', 'spark', 'very', 'very', 'much'],\n",
        "            ['everyone', 'should', 'use', 'spark']\n",
        "        ]\n",
        "    })\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+\n",
            "|terms                                      |\n",
            "+-------------------------------------------+\n",
            "|[spark, spark, spark, is, awesome, awesome]|\n",
            "|[I, love, spark, very, very, much]         |\n",
            "|[everyone, should, use, spark]             |\n",
            "+-------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diYnMiQgRcpJ"
      },
      "source": [
        "## HashingTF\n",
        "\n",
        "The **numFeatures** paramter takes an integer, which should be larger than the total number of terms in the corpus. And it should be a power of two so that features are mapped evenly to columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4yqZ-HsRHVY"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "hashtf = HashingTF(numFeatures=2**4, inputCol='terms', outputCol='features(numFeatures), [index], [term frequency]')\n",
        "stages = [hashtf]\n",
        "pipeline = Pipeline(stages=stages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUEbrkQbRHYS",
        "outputId": "4073ecfe-3741-44fc-decf-1bab6c5dbe4e"
      },
      "source": [
        "pipeline.fit(df).transform(df).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+------------------------------------------------+\n",
            "|terms                                      |features(numFeatures), [index], [term frequency]|\n",
            "+-------------------------------------------+------------------------------------------------+\n",
            "|[spark, spark, spark, is, awesome, awesome]|(16,[6,9],[3.0,3.0])                            |\n",
            "|[I, love, spark, very, very, much]         |(16,[0,6,8,12],[1.0,1.0,2.0,2.0])               |\n",
            "|[everyone, should, use, spark]             |(16,[5,6,13],[1.0,1.0,2.0])                     |\n",
            "+-------------------------------------------+------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX-okJBsS8YI"
      },
      "source": [
        "You may note that the first document has three distinct terms, but only two term frequencies are obtained. This apparent discrepancy is due to a **hashing collision**: both `spark` and `is` are getting hashed to `1`. The term frequency for index `1` in the first document is `4.0` corresponding to the three counts of `spark` and the one count of `is`. The likelihood of a hashing collision can be reduced by increasing the `numFeatures` parameter passed to the `HashingTF` function (the default for example is $2^{18} = 262,144$)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hashtf = HashingTF(numFeatures=2**10, inputCol='terms', outputCol='features(numFeatures), [index], [term frequency]')\n",
        "stages = [hashtf]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "pipeline.fit(df).transform(df).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvwZfHFQWDPz",
        "outputId": "e42f06d6-600b-4393-ef4b-9764f618796a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+--------------------------------------------------+\n",
            "|terms                                      |features(numFeatures), [index], [term frequency]  |\n",
            "+-------------------------------------------+--------------------------------------------------+\n",
            "|[spark, spark, spark, is, awesome, awesome]|(1024,[345,502,761],[1.0,3.0,2.0])                |\n",
            "|[I, love, spark, very, very, much]         |(1024,[112,120,502,556,988],[1.0,2.0,1.0,1.0,1.0])|\n",
            "|[everyone, should, use, spark]             |(1024,[237,413,502,885],[1.0,1.0,1.0,1.0])        |\n",
            "+-------------------------------------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74x6_GzOS8cq"
      },
      "source": [
        "## CountVectorizer\n",
        "\n",
        "The **`CountVectorizer()`** function has three parameters to control which terms will be kept as features.\n",
        "\n",
        "* minTF: features that has term frequency less than minTF will be removed. If minTF=1minTF=1, then no features will be removed.\n",
        "* minDF: features that has document frequency less than minDF will be removed. If minDF=1minDF=1, then no features will be removed.\n",
        "* vocabSize: keep terms of the top vocabSize frequencies.\n",
        "\n",
        "In the example below, the `minTF=1.0,minDF=1.0minTF=1.0,minDF=1.0` and `vocabSize=20vocabSize=20`, which is larger than the total number of terms. Therefore, all features (terms) will be kept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIBiOkTqRHau"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "countvectorizer = CountVectorizer(minTF=1.0, minDF=1.0, vocabSize=20, \n",
        "                                  inputCol='terms', outputCol='features(vocabSize), [index], [term frequency]')\n",
        "stages = [countvectorizer]\n",
        "pipeline = Pipeline(stages=stages)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHmHHtTBRHeB",
        "outputId": "5c7929be-741a-49ef-eb32-22b0f0963af4"
      },
      "source": [
        "pipeline.fit(df).transform(df).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+----------------------------------------------+\n",
            "|terms                                      |features(vocabSize), [index], [term frequency]|\n",
            "+-------------------------------------------+----------------------------------------------+\n",
            "|[spark, spark, spark, is, awesome, awesome]|(10,[0,1,6],[3.0,2.0,1.0])                    |\n",
            "|[I, love, spark, very, very, much]         |(10,[0,2,3,7,9],[1.0,2.0,1.0,1.0,1.0])        |\n",
            "|[everyone, should, use, spark]             |(10,[0,4,5,8],[1.0,1.0,1.0,1.0])              |\n",
            "+-------------------------------------------+----------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPDGF3eTIaN"
      },
      "source": [
        "Now, lets use the StringIndexer() to index the corpus and see if the results is consistant with the CountVectorizer() method.\n",
        "\n",
        "### `flatMap` documents so that each row has a single term."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW3AQk8eRHgZ",
        "outputId": "db965a6e-8c38-4caf-ec33-e88c67e043a9"
      },
      "source": [
        "from pyspark.sql.types import StringType\n",
        "df_vocab = df.select('terms').rdd.\\\n",
        "            flatMap(lambda x: x[0]).\\\n",
        "            toDF(schema=StringType()).toDF('terms')\n",
        "df_vocab.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|   terms|\n",
            "+--------+\n",
            "|   spark|\n",
            "|   spark|\n",
            "|   spark|\n",
            "|      is|\n",
            "| awesome|\n",
            "| awesome|\n",
            "|       I|\n",
            "|    love|\n",
            "|   spark|\n",
            "|    very|\n",
            "|    very|\n",
            "|    much|\n",
            "|everyone|\n",
            "|  should|\n",
            "|     use|\n",
            "|   spark|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm8WmkvmTNQD"
      },
      "source": [
        "### Calculate term frequencies in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmpjMHO8TNeq",
        "outputId": "6c82aa1c-8ace-4884-af61-3a040ba0a6a1"
      },
      "source": [
        "vocab_freq = df_vocab.rdd.countByValue()\n",
        "pdf = pd.DataFrame({\n",
        "        'term': list(vocab_freq.keys()),\n",
        "        'frequency': list(vocab_freq.values())\n",
        "    })\n",
        "pdf\n",
        "tf = spark.createDataFrame(pdf).orderBy('frequency', ascending=False)\n",
        "tf.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|      term|frequency|\n",
            "+----------+---------+\n",
            "|   {spark}|        5|\n",
            "|    {very}|        2|\n",
            "| {awesome}|        2|\n",
            "|    {much}|        1|\n",
            "|  {should}|        1|\n",
            "|{everyone}|        1|\n",
            "|     {use}|        1|\n",
            "|      {is}|        1|\n",
            "|       {I}|        1|\n",
            "|    {love}|        1|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ7ylGb0TTEa"
      },
      "source": [
        "## Apply `StringIndexer()` to df_vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7D4f-22TNhp"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "stringindexer = StringIndexer(inputCol='terms', outputCol='StringIndexer(index)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOEwmTMLTNmB",
        "outputId": "eaec111d-7a5f-4b5f-c661-5d5488471ce3"
      },
      "source": [
        "stringindexer.fit(df_vocab).transform(df_vocab).\\\n",
        "    distinct().\\\n",
        "    orderBy('StringIndexer(index)').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|   terms|StringIndexer(index)|\n",
            "+--------+--------------------+\n",
            "|   spark|                 0.0|\n",
            "| awesome|                 1.0|\n",
            "|    very|                 2.0|\n",
            "|       I|                 3.0|\n",
            "|everyone|                 4.0|\n",
            "|      is|                 5.0|\n",
            "|    love|                 6.0|\n",
            "|    much|                 7.0|\n",
            "|  should|                 8.0|\n",
            "|     use|                 9.0|\n",
            "+--------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqED3qvhTbag"
      },
      "source": [
        "The indexing result is consistant for the first three terms. The rest of terms have the same frequency which is 1. These terms can not be sorted by frequency. This might be the reason that their indices don’t match the results from the CountVectorizer() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "escWb1yDRHip"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aXpCFu5RHk0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}